{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7ba8b5-617a-45c5-a0b5-0b2fdcbd872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5169f6f1-9759-405f-ace0-452764f9a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b14c5c27-2302-48b8-8d4a-7210ef516fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_user_data():\n",
    "    user_data = {}\n",
    "\n",
    "    # Collect personal information\n",
    "    user_data['name'] = input(\"Enter your name: \")\n",
    "    user_data['email'] = input(\"Enter your email: \")\n",
    "    user_data['phone'] = input(\"Enter your phone number: \")\n",
    "    user_data['linkedin'] = input(\"Enter your LinkedIn URL: \")\n",
    "    user_data['github'] = input(\"Enter your GitHub URL: \")\n",
    "\n",
    "    # Collect education details\n",
    "    education = []\n",
    "    while True:\n",
    "        degree = input(\"Enter degree (or type 'done' to finish): \")\n",
    "        if degree.lower() == 'done':\n",
    "            break\n",
    "        institution = input(\"Enter institution name: \")\n",
    "        year = input(\"Enter year of graduation: \")\n",
    "        education.append({\n",
    "            'degree': degree,\n",
    "            'institution': institution,\n",
    "            'year': year\n",
    "        })\n",
    "    user_data['education'] = education\n",
    "\n",
    "    # Collect work experience\n",
    "    experience = []\n",
    "    while True:\n",
    "        job_title = input(\"Enter job title (or type 'done' to finish): \")\n",
    "        if job_title.lower() == 'done':\n",
    "            break\n",
    "        company = input(\"Enter company name: \")\n",
    "        start_date = input(\"Enter start date: \")\n",
    "        end_date = input(\"Enter end date: \")\n",
    "        responsibilities = input(\"Enter responsibilities: \")\n",
    "        experience.append({\n",
    "            'job_title': job_title,\n",
    "            'company': company,\n",
    "            'start_date': start_date,\n",
    "            'end_date': end_date,\n",
    "            'responsibilities': responsibilities\n",
    "        })\n",
    "    user_data['experience'] = experience\n",
    "\n",
    "    # Collect skills\n",
    "    skills = input(\"Enter your skills (comma separated): \").split(',')\n",
    "    user_data['skills'] = [skill.strip() for skill in skills]\n",
    "\n",
    "    return user_data,education,skills,experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d33242-0482-494a-8f13-46791333ea11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your name:  Muhammad Ahsan\n",
      "Enter your email:  ahsanp899@gmail.com\n",
      "Enter your phone number:  0322-9223388\n",
      "Enter your LinkedIn URL:  www.linkedin.com/in/ahsan-vip\n",
      "Enter your GitHub URL:  https://github.com/Ahsanvip\n",
      "Enter degree (or type 'done' to finish):  Bs. Computer science\n",
      "Enter institution name:  UET \n",
      "Enter year of graduation:  2024\n",
      "Enter degree (or type 'done' to finish):  done\n",
      "Enter job title (or type 'done' to finish):  Open Source Developer\n",
      "Enter company name:  github.com\n",
      "Enter start date:  2024\n",
      "Enter end date:  2025\n",
      "Enter responsibilities:  Built a comprehensive project on customer churn prediction using Dense Neural Networks, showcasing proficiency in deep learning methodologies. Utilized TensorFlow and Keras for efficient model implementation, ensuring scalability and accuracy. Conducted an in-depth analysis of customer data to identify key churn indicators and improve retention strategies. Developed and fine-tuned the model to achieve significant accuracy improvements. Integrated visualizations to interpret model predictions, providing actionable insights for customer engagement. Built a model for sleep disorder prediction with Random Forest (87% accuracy), utilizing preprocessing pipelines and visualized insights with Matplotlib. Predicted mood categories (Positive, Neutral, Negative) using Logistic Regression, conducting feature engineering and preprocessing to improve performance. Developed a book genre preference prediction model with Random Forest, implementing efficient encoding and preprocessing via ColumnTransformer. Built an MNIST handwritten digit classification model using CNNs in TensorFlow, achieving high accuracy through hyperparameter tuning and dropout optimization. Created a reusable ML pipeline for data cleaning and transformation tasks, applying the pipeline to various datasets for versatile use cases.\n",
      "Enter job title (or type 'done' to finish):  done\n",
      "Enter your skills (comma separated):  Machine Learning & AI Predictive Analytics: Time Series Forecasting, Regression Models Recommendation Systems: Collaborative Filtering, Matrix Factorization, Hybrid Systems Speech and Audio Processing: Audio Classification, Speech Recognition, NLP Frameworks & Tools TensorFlow, Keras, Scikit-Learn, PyTorch NLP Frameworks: Hugging Face, SpaCy Audio Processing: Librosa, SpeechRecognition Data Manipulation & Engineering Python (NumPy, Pandas, Matplotlib, Plotly) SQL, Feature Engineering, Big Data Technologies (Spark, Hadoop) Deployment & Monitoring Cloud Platforms: AWS (SageMaker), Google Cloud AI Platform, Azure ML Model Lifecycle Management: Deployment, Monitoring, A/B Testing\n"
     ]
    }
   ],
   "source": [
    "userdata,education,skills,experience=collect_user_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975284e5-f3a1-4940-a04f-a56bd7a279e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'job_title': 'Open Source Developer',\n",
       "  'company': 'github.com',\n",
       "  'start_date': '2024',\n",
       "  'end_date': '2025',\n",
       "  'responsibilities': 'Built a comprehensive project on customer churn prediction using Dense Neural Networks, showcasing proficiency in deep learning methodologies. Utilized TensorFlow and Keras for efficient model implementation, ensuring scalability and accuracy. Conducted an in-depth analysis of customer data to identify key churn indicators and improve retention strategies. Developed and fine-tuned the model to achieve significant accuracy improvements. Integrated visualizations to interpret model predictions, providing actionable insights for customer engagement. Built a model for sleep disorder prediction with Random Forest (87% accuracy), utilizing preprocessing pipelines and visualized insights with Matplotlib. Predicted mood categories (Positive, Neutral, Negative) using Logistic Regression, conducting feature engineering and preprocessing to improve performance. Developed a book genre preference prediction model with Random Forest, implementing efficient encoding and preprocessing via ColumnTransformer. Built an MNIST handwritten digit classification model using CNNs in TensorFlow, achieving high accuracy through hyperparameter tuning and dropout optimization. Created a reusable ML pipeline for data cleaning and transformation tasks, applying the pipeline to various datasets for versatile use cases.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb66037c-7115-4a35-b8bf-2aaefc82dfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Groq API key:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e8641633-33c0-4b88-82df-f91a743c72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up llM\n",
    "llm=ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "591796ca-aa4e-4165-b1c8-89ffeb6b6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ba409c1-d071-472f-a296-828404c82e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword prompt\n",
    "keyword_pr=PromptTemplate(\n",
    "    input_variables=[\"Job_description\"],\n",
    "    template=\"\"\"\" \n",
    "     Analyze the following job description and extract a list of the most relevant keywords and phrases. \n",
    "    Focus on skills, qualifications, technologies, and responsibilities:\n",
    "    \n",
    "    Job Description:\n",
    "    {Job_description}\n",
    "    \n",
    "    Return the keywords as a comma-separated list.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e09f06d9-cf0a-4f59-8373-fb939c1400cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#personal info prompt \n",
    "personal_pr=PromptTemplate(\n",
    "    input_variables=[\"name\", \"email\", \"phone\", \"linkedin\", \"github\",\"keywords\"],\n",
    "    template=\"\"\"\n",
    "    Format the output as:\n",
    "    - Name: [Name]\n",
    "    - Email: [Email]\n",
    "    - Phone: [Phone]\n",
    "    - LinkedIn: [LinkedIn URL]\n",
    "    - GitHub: [GitHub URL]\n",
    "    note:only give usable output , do not add notes , explaination of what you did and do not try to make words bold with **\n",
    "    Name: {name}\n",
    "    Email: {email}\n",
    "    Phone: {phone}\n",
    "    LinkedIn: {linkedin}\n",
    "    GitHub: {github}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "15958e2d-8ec1-488c-bbb4-30ddb339e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd=\"\"\" \n",
    "    Inovaqo is on the lookout for an experienced and skilled 𝐏𝐲𝐭𝐡𝐨𝐧/𝐀𝐈 𝐃𝐞𝐯𝐞𝐥𝐨𝐩𝐞𝐫 to join our dynamic team in Lahore! If you have at least 3 years of hands-on experience in Python programming and AI/ML, we want to hear from you! Check out the key responsibilities and requirements below:\n",
    "\n",
    "Your Super Powers: \n",
    "1️⃣ Design, develop, and optimize AI-driven chatbots tailored to specific business needs.\n",
    "2️⃣ Create, curate, and manage custom datasets, including transcription of audio files for training purposes. \n",
    "3️⃣ Train large language models (LLMs) on proprietary datasets to enhance chatbot capabilities. \n",
    "4️⃣ Utilize Lang Chain and other ML frameworks to develop and enhance AI solutions. \n",
    "5️⃣ Optimize and fine-tune AI models to improve performance and accuracy. \n",
    "6️⃣ Develop strategies for prompt engineering and fine-tuning to achieve desired chatbot behavior. \n",
    "7️⃣ Conduct regular performance evaluations and implement improvements based on feedback and metrics. \n",
    "8️⃣ Stay updated with the latest advancements in AI/ML and incorporate relevant techniques and tools into development processes.\n",
    "\n",
    "\n",
    "What We’re Looking For:\n",
    "\n",
    "➡️Bachelor’s or Master’s degree in Computer Science, Artificial Intelligence, Machine Learning, or a related field.\n",
    "➡️3+ years of relevant experience in Python programming and developing AI/ML applications.\n",
    "➡️Proven experience in developing chatbots and conversational AI solutions, with or without reliance on external APIs like OpenAI.\n",
    "➡️Knowledge of prompt engineering and techniques for improving AI model responses.\n",
    "Proficient in machine learning frameworks and tools such as TensorFlow, PyTorch, Scikit-learn, and Lang Chain.\n",
    "➡️Experience with image processing libraries like OpenCV, Pillow, or Scikit-image.\n",
    "➡️Strong understanding of natural language processing (NLP) and experience with NLP libraries and frameworks (e.g., NLTK, spaCy, Hugging Face Transformers).\n",
    "➡️Hands-on experience in training and fine-tuning large language models (e.g., GPT, BERT) on custom datasets.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "275021b8-99e3-43e7-b512-0ca734c46fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#personal summary prompt\n",
    "summary='''Motivated Machine Learning enthusiast with expertise in end-to-end ML solutions. Skilled in data preprocessing, model evaluation, and problem-solving. Seeking an Associate Software Engineer position in ML/AI to apply and expand technical skills.'''\n",
    "summary_pr=PromptTemplate(\n",
    "    input_variable=[\"summary\",\"keywords\"],\n",
    "    template=\"\"\" \n",
    "         Generate a professional and concise \"Summary\" section for a resume, tailored to the following keywords:\n",
    "    {keywords}\n",
    "     note:only give usable output , do not add notes , explaination of what you did and do not try to make words bold with **\n",
    "    summary:{summary}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f12e61b0-a860-431c-acd4-49f8bbc1c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experience prompt\n",
    "exp_pr=PromptTemplate(\n",
    "    input_variables=[\"experiences\",\"keywords\"],\n",
    "    template=\"\"\"\n",
    "    give precise output. keep it short yet effective keep the orginal format. \n",
    "    Format the following job experiences to highlight their relevance to these keywords:\n",
    "    {keywords}\n",
    "    note:only give usable output , do not add notes , explaination of what you did and do not try to make words bold with **\n",
    "    job experiences for a professional resume:\n",
    "    {experiences}\n",
    "\n",
    "    output format :\n",
    "    Job Title , company \n",
    "    date\n",
    "    Precise Responsibilites\n",
    "    \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6b38170d-7a14-4cd7-a427-a099b220599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Education prompt\n",
    "edu_pr=PromptTemplate(\n",
    "    input_variables=[\"Education\"],\n",
    "    template=\"\"\"\n",
    "    instructions:\n",
    "    wrtie education section for a resume based on provided education information.\n",
    "    note:only give usable output , do not add notes , explaination of what you did and do not try to make words bold with **\n",
    "\n",
    "    Output Format:\n",
    "    University Name\n",
    "    Degree\n",
    "    year of completion\n",
    "\n",
    "    Note: Strictly follow the output format and do not add any irrelevant in the output.\n",
    "    {Education}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "87a13e13-d7f3-44ea-a908-20b4d39c2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skill prompt\n",
    "skills_prompt = PromptTemplate(\n",
    "   input_variables=[\"skills\",\"keywords\",\"Job_description\"],\n",
    "    template=\"\"\"\n",
    "    Create a 'Skills' section for a professional resume using the provided keywords. Tailor this section to a job description, ensuring that the keywords are extracted from the description.\n",
    "\n",
    "- **Keywords**: {keywords}\n",
    "- **Skills**: {skills}\n",
    "- **job description**: {Job_description}\n",
    "\n",
    "# Output Format\n",
    "\n",
    "- The output should be in a comma-separated format with no additional text or explanation.\n",
    "- The format should include only the following sections:\n",
    "  - **Languages**: [list of languages]\n",
    "  - **Frameworks**: [list of frameworks]\n",
    "  - **Soft Skills**: [list of soft skills]\n",
    "\n",
    "# Examples(this is only for reference , these are not true values.)\n",
    "\n",
    "- **Languages**: python, java, sql\n",
    "- **Frameworks**: Tensorflow, Langchain, pandas , Apache Spark \n",
    "- **Soft Skills**: Team collaboration, Analytical thinking\n",
    "\n",
    "# Notes\n",
    "\n",
    "- Ensure that no additional sections or text are included beyond the specified format. and do not try to make words bold with **\n",
    "- Only include skills that are relevant to the provided keywords and job description.\n",
    "    \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "19af9928-2bf4-4dfe-8a9d-f75acd67b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "personal_info_chain = LLMChain(llm=llm, prompt=personal_pr,output_key=\"profile\")\n",
    "experience_chain = LLMChain(llm=llm, prompt=exp_pr,output_key=\"experience_section\")\n",
    "skills_chain = LLMChain(llm=llm, prompt=skills_prompt,output_key='skills_section')\n",
    "summary_chain=LLMChain(llm=llm, prompt=summary_pr,output_key=\"summary_section\")\n",
    "keyword_chain=LLMChain(llm=llm,prompt=keyword_pr,output_key='keywords')\n",
    "education_chain=LLMChain(llm=llm,prompt=edu_pr,output_key='education_section')\n",
    "\n",
    "# Combine chains into a SequentialChain\n",
    "resume_chain = SequentialChain(\n",
    "    chains=[keyword_chain,personal_info_chain, experience_chain, skills_chain,summary_chain,education_chain],\n",
    "    input_variables=[\"Job_description\",\"name\", \"email\", \"phone\", \"linkedin\", \"github\", \"summary\", \"experiences\", \"skills\",\"Education\"],\n",
    "    output_variables=[\"keywords\",\"profile\", \"experience_section\", \"skills_section\",\"summary_section\",\"education_section\"] # Specify the individual sections as output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1740c5c9-291d-4a40-9f62-17f0fc577fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1fea86b-e581-4f24-a681-b15d4eac7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9172d1c7-3cac-4f03-b91d-6768fdf9c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = resume_chain.invoke({\n",
    "    \"name\": userdata[\"name\"],\n",
    "    \"email\": userdata[\"email\"],\n",
    "    \"phone\": userdata[\"phone\"],\n",
    "    \"linkedin\": userdata[\"linkedin\"],\n",
    "    \"github\": userdata[\"github\"],\n",
    "    \"summary\": summary,\n",
    "    \"experiences\": experience,\n",
    "    \"skills\": skills,\n",
    "    \"Job_description\":jd,\n",
    "    \"Education\":education\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69a5d980-2728-4665-a04d-684ed507725e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Muhammad Ahsan', 'email': 'ahsanp899@gmail.com', 'phone': '0322-9223388', 'linkedin': 'www.linkedin.com/in/ahsan-vip', 'github': 'https://github.com/Ahsanvip', 'summary': 'Motivated Machine Learning enthusiast with expertise in end-to-end ML solutions. Skilled in data preprocessing, model evaluation, and problem-solving. Seeking an Associate Software Engineer position in ML/AI to apply and expand technical skills.', 'experiences': [{'job_title': 'Open Source Developer', 'company': 'github.com', 'start_date': '2024', 'end_date': '2025', 'responsibilities': 'Built a comprehensive project on customer churn prediction using Dense Neural Networks, showcasing proficiency in deep learning methodologies. Utilized TensorFlow and Keras for efficient model implementation, ensuring scalability and accuracy. Conducted an in-depth analysis of customer data to identify key churn indicators and improve retention strategies. Developed and fine-tuned the model to achieve significant accuracy improvements. Integrated visualizations to interpret model predictions, providing actionable insights for customer engagement. Built a model for sleep disorder prediction with Random Forest (87% accuracy), utilizing preprocessing pipelines and visualized insights with Matplotlib. Predicted mood categories (Positive, Neutral, Negative) using Logistic Regression, conducting feature engineering and preprocessing to improve performance. Developed a book genre preference prediction model with Random Forest, implementing efficient encoding and preprocessing via ColumnTransformer. Built an MNIST handwritten digit classification model using CNNs in TensorFlow, achieving high accuracy through hyperparameter tuning and dropout optimization. Created a reusable ML pipeline for data cleaning and transformation tasks, applying the pipeline to various datasets for versatile use cases.'}], 'skills': ['Machine Learning & AI Predictive Analytics: Time Series Forecasting', ' Regression Models Recommendation Systems: Collaborative Filtering', ' Matrix Factorization', ' Hybrid Systems Speech and Audio Processing: Audio Classification', ' Speech Recognition', ' NLP Frameworks & Tools TensorFlow', ' Keras', ' Scikit-Learn', ' PyTorch NLP Frameworks: Hugging Face', ' SpaCy Audio Processing: Librosa', ' SpeechRecognition Data Manipulation & Engineering Python (NumPy', ' Pandas', ' Matplotlib', ' Plotly) SQL', ' Feature Engineering', ' Big Data Technologies (Spark', ' Hadoop) Deployment & Monitoring Cloud Platforms: AWS (SageMaker)', ' Google Cloud AI Platform', ' Azure ML Model Lifecycle Management: Deployment', ' Monitoring', ' A/B Testing'], 'Job_description': \"Devsinc is looking for a talented Software Engineer (AI/ML) to join our innovative team. In this role, you will have the opportunity to work on cutting-edge artificial intelligence and machine learning projects that impact our products and services. You will collaborate with experienced engineers and data scientists to develop and implement AI-driven solutions that enhance user experience and increase operational efficiency.\\n\\nResponsibilities:\\n\\nDesign, develop, and implement machine learning models and algorithms to solve complex problems\\nPerform data preprocessing and feature engineering to prepare data for analysis and model training\\nCollaborate with cross-functional teams to understand project requirements and deliver effective AI solutions\\nEvaluate the performance of models and fine-tune algorithms to optimize results\\nDocument processes, methodologies, and results for future reference and knowledge sharing\\nStay current with the latest developments in AI and machine learning technologies\\n\\n\\nRequirements\\n\\nRequirements:\\n\\nExperience: 1-2 years Bachelor's degree in Computer Science, Data Science, or a related field\\nStrong programming skills in languages such as Python, Java, or C\\nFamiliarity with machine learning frameworks (e.g., TensorFlow, PyTorch, Scikit-learn)\\nUnderstanding of fundamental concepts in machine learning and artificial intelligence\\nHands-on experience with data manipulation and analysis tools (e.g., Pandas, NumPy)\\nAbility to work collaboratively in a team environment\\nExcellent problem-solving and analytical skills\\nPrevious experience with AI/ML projects is advantageous but not required\\n\\n\\nBenefits\\n\\nPrivate Health Insurance\\nPension Plan\\nPaid Time Off\\nWork From Home\\nTraining & Development\\nPerformance Bonus\", 'keywords': 'Software Engineer, AI, ML, Machine Learning, Artificial Intelligence, Python, Java, C, TensorFlow, PyTorch, Scikit-learn, Data Science, Data Preprocessing, Feature Engineering, Data Analysis, Algorithm Development, Model Training, Collaboration, Problem-Solving, Analytical Skills, Data Manipulation, Pandas, NumPy, Team Environment, AI/ML Projects, Computer Science.', 'profile': 'Name: Muhammad Ahsan\\nEmail: ahsanp899@gmail.com\\nPhone: 0322-9223388\\nLinkedIn: www.linkedin.com/in/ahsan-vip\\nGitHub: https://github.com/Ahsanvip\\nSummary: Results-driven Software Engineer with strong proficiency in AI and ML, leveraging Python, Java, and C to develop and deploy scalable models using TensorFlow, PyTorch, and Scikit-learn. Adept in data science, data analysis, and algorithm development, with a solid foundation in computer science and a passion for collaborating on innovative AI/ML projects, driving data-driven solutions, and fostering a team environment.', 'experience_section': 'Software Engineer with expertise in AI and ML, utilizing Python, TensorFlow, and PyTorch to develop predictive models. Proficient in data science, preprocessing, feature engineering, and algorithm development. Utilized scikit-learn, Pandas, and NumPy for data manipulation and analysis. Collaborated on projects, applying problem-solving and analytical skills in a team environment. Developed and trained models, including customer churn prediction, sleep disorder prediction, mood category prediction, and handwritten digit classification, achieving high accuracy through hyperparameter tuning and optimization.', 'skills_section': 'Machine Learning, Artificial Intelligence, Python, Java, C, TensorFlow, PyTorch, Data Science, Data Analysis, Algorithm Development'}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "955c7000-2b73-4695-857d-d9fd84e35984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Resume:\n",
      "\n",
      "==============================\n",
      "           Resume\n",
      "==============================\n",
      "\n",
      "- Name: Muhammad Ahsan\n",
      "- Email: ahsanp899@gmail.com\n",
      "- Phone: 0322-9223388\n",
      "- LinkedIn: www.linkedin.com/in/ahsan-vip\n",
      "- GitHub: https://github.com/Ahsanvip\n",
      "\n",
      "==============================\n",
      "summary:\n",
      "==============================\n",
      "Summary: Results-driven AI professional with expertise in Python, Machine Learning, and Natural Language Processing, proficient in developing and optimizing Large Language Models using TensorFlow, PyTorch, and Hugging Face Transformers, with experience in Conversational AI, Image Processing, and Data Science, seeking a challenging role in AI Model Development and AI Solutions.\n",
      "\n",
      "==============================\n",
      "Professional Experience:\n",
      "==============================\n",
      "Open Source Developer , github.com \n",
      "2024 - 2025\n",
      "Built and fine-tuned deep learning models using TensorFlow and Keras for customer churn prediction and sleep disorder prediction, achieving high accuracy with Dense Neural Networks, Random Forest, and CNNs, and developed reusable ML pipelines for data cleaning and transformation tasks.\n",
      "\n",
      "==============================\n",
      "Skills:\n",
      "==============================\n",
      "Languages: python\n",
      "Frameworks: TensorFlow, PyTorch, Scikit-learn, Lang Chain, OpenCV, Pillow, Scikit-image, NLTK, spaCy, Hugging Face Transformers\n",
      "Soft Skills: Team collaboration, Analytical thinking, Problem-solving, Time management, Performance evaluation, Prompt engineering\n",
      "\n",
      "==============================\n",
      "Education:\n",
      "==============================\n",
      "UET \n",
      "Bs. Computer science\n",
      "2024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formatted_output = f\"\"\"\n",
    "==============================\n",
    "           Resume\n",
    "==============================\n",
    "\n",
    "{output['profile']}\n",
    "\n",
    "==============================\n",
    "summary:\n",
    "==============================\n",
    "{output['summary_section']}\n",
    "\n",
    "==============================\n",
    "Professional Experience:\n",
    "==============================\n",
    "{output['experience_section']}\n",
    "\n",
    "==============================\n",
    "Skills:\n",
    "==============================\n",
    "{output['skills_section']}\n",
    "\n",
    "==============================\n",
    "Education:\n",
    "==============================\n",
    "{output['education_section']}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Formatted Resume:\")\n",
    "print(formatted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57484fe3-974d-43e4-bde6-6fdb13ea9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['profile']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "813d9ea8-9d51-4198-a717-afa0d1483f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fpdf\n",
      "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: fpdf\n",
      "  Building wheel for fpdf (setup.py): started\n",
      "  Building wheel for fpdf (setup.py): finished with status 'done'\n",
      "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40714 sha256=1af31d94b2817056c1ff794516c1f4327be8eb6030d48a7bd69a3d7e00bca08d\n",
      "  Stored in directory: c:\\users\\opm\\appdata\\local\\pip\\cache\\wheels\\6e\\62\\11\\dc73d78e40a218ad52e7451f30166e94491be013a7850b5d75\n",
      "Successfully built fpdf\n",
      "Installing collected packages: fpdf\n",
      "Successfully installed fpdf-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fpdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "72b011f3-8067-4a6a-b00e-773580db0388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Filepath for saving output data\n",
    "OUTPUT_FILE = \"rresume_data.json\"\n",
    "\n",
    "# Save and load functions\n",
    "def save_output_to_file(output, filepath=OUTPUT_FILE):\n",
    "    \"\"\"Save the output data to a JSON file.\"\"\"\n",
    "    with open(filepath, \"w\") as file:\n",
    "        json.dump(output, file, indent=4)\n",
    "    print(f\"Output saved to {filepath}.\")\n",
    "\n",
    "def load_output_from_file(filepath=OUTPUT_FILE):\n",
    "    \"\"\"Load the output data from a JSON file.\"\"\"\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, \"r\") as file:\n",
    "            return json.load(file)\n",
    "    print(f\"No existing file found at {filepath}. Starting fresh.\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f5f61153-6e5f-4d52-b796-6953ffeaeb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to rresume_data.json.\n"
     ]
    }
   ],
   "source": [
    "save_output_to_file(output,filepath=OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6c75a6-06f7-4072-adda-da10fd015bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
